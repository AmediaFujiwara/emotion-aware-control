# 感情をリスク信号として扱う安定性優先の意思決定・制御フレームワーク

## 要旨

本研究は，不安・恐怖・焦燥といった感情を「排除すべきノイズ」ではなく，「破綻リスクを示す入力信号」として扱う意思決定・制御フレームワークを提案する．  
人間の意思決定が破綻する要因は，合理性の欠如ではなく，境界侵害，制御不能性，および喪失リスクの累積にあると考えられる．  
本研究では，感情入力を三つの構造的リスク軸（境界侵害・制御不能・喪失）に分解し，それに基づいて環境・制度・手順・非介入からなる介入方策を選択するフィードバック制御モデルを構成する．  
さらに，過剰な最適化や介入による不安定化を防ぐために，「非介入（Non-Intervention）」を制御ポリシーの一部として明示的に組み込む．  
本フレームワークは，人間の感情と価値を中心に据えつつ，長期的な安定性（破綻回避）を最大化する意思決定支援および人間中心AI設計の基盤となることを目指す．

---

## 1. はじめに

人間の意思決定はしばしば「感情的で非合理的」と評される．しかし現実には，問題は感情そのものではなく，感情が示しているリスク構造を適切に扱えないことにある．  
不安や恐怖は，生活・仕事・人間関係・資産といったシステムが破綻に近づいていることを知らせる重要な信号である．  
しかし多くの意思決定支援やAIシステムは，この感情信号を無視するか，単なる主観ノイズとして扱ってきた．  
その結果，短期的な最適化は達成されても，長期的な疲弊や破綻が引き起こされることが多い．  

本研究の目的は，感情を入力として取り込み，人間が壊れないこと（安定性）を最上位目的とする意思決定・制御の枠組みを構築することである．

## 2. フレームワークの全体像

本研究が提案するフレームワークは，人間の感情を「設計に利用可能なリスク信号」として扱い，長期的な破綻を防ぐための制御ループとして定式化される．  
その中心となるのが，三つの構造的リスク軸と，それに基づく介入・非介入の選択である．

### 2.1 感情から構造への翻訳

人間が不安，恐怖，怒り，悲しみなどの感情を感じるとき，それは単なる主観的な気分ではなく，外部環境と自己の関係が危険な状態に近づいていることを示す信号である．  
しかし感情はそのままでは行動設計に使いにくいため，本フレームワークでは感情を以下の三つの構造的リスクに翻訳する．

### 2.2 三つの構造的リスク軸

感情信号は，次の三つの軸からなる構造的リスクベクトルとして表現される．

#### (1) 境界侵害（Boundary Violation）
本来守られるべき生活・回復・思考の領域に，仕事・他者・責任・数値評価などが侵入している状態を表す．  
例えば，「仕事の評価が私生活の安心感を破壊している」「他人の視線が集中や作業を妨げている」といった状態は，境界侵害として捉えられる．

#### (2) 制御不能（Uncontrollability）
その問題が自分の行動や努力で制御可能か，あるいは外生的要因に支配されているかを示す．  
市場変動，他人の意思，組織の評価制度などは，多くの場合個人が直接制御できない変数であり，高い制御不能性を持つ．

#### (3) 喪失・予期的喪失（Loss / Anticipated Loss）
現在または将来において失われる可能性のあるものの大きさを表す．  
心身の健康，生活の安定，家族関係，キャリアなど，回復不能または回復困難な損失が見込まれる場合，この軸は高くなる．

これら三つの軸により，感情は「何が危険なのか」「どこが壊れそうなのか」を示す設計可能な情報へと変換される．

### 2.3 介入としての設計認知

三つのリスク軸が特定された後，本フレームワークは以下の三種類の介入を用いてシステムを再設計する．

- **環境（Environment）**：物理的・情報的環境の変更（在宅勤務，作業場所の分離など）
- **制度（Institution）**：ルールや契約，制度の変更（役割定義，制度利用など）
- **手順（Procedure）**：行動や意思決定の手順の設計（売買ルール，対応テンプレートなど）

これらはすべて，「壊れない条件」を満たすように構造を再設計するための制御入力である．

### 2.4 非介入（Non-Intervention: NI）

しかし，すべての問題が設計や介入によって解決できるわけではない．  
制御不能性が高く，かつ介入コスト（疲労・対人摩擦・資源消費）が大きい場合，過剰な介入はかえって不安定化を招く．

そのため本フレームワークでは，「何もしないこと」を明示的な制御方策として定義する．  
これを **非介入（Non-Intervention, NI）** と呼ぶ．

NIは，問題を放置することではなく，
「設計しても安定性が改善しない領域に対して，意図的に介入しない」
という戦略的選択である．

### 2.5 安定性優先の制御ループ

以上を統合すると，本フレームワークは以下の制御ループとして表現される．

1. 出来事と感情の発生  
2. メタ認知による観測  
3. 三軸による構造的リスクの同定  
4. 環境・制度・手順・非介入の選択  
5. 安定性の回復または維持  

このループを繰り返すことで，人間は短期的な最適化ではなく，
「壊れないこと」を最優先とする意思決定を行うことができる．

## 3. 数式による定式化

本節では，前節で述べた三軸フレームワークと非介入（NI）を，
数理的な制御モデルとして表現する．
目的は「人間の感情と状況を入力とし，安定性を最大化する行動方針を選択する」ことである．

### 3.1 状態と感情入力

時刻 t において，人間は外部の出来事と内部の感情を同時に経験している．
これを以下の内部状態としてまとめる．

\[
s_t = \phi(x_t, e_t, g_t)
\]

ここで，

- \(x_t\)：外部の出来事（仕事，市場，対人関係など）
- \(e_t\)：感情信号（不安，恐怖，怒り，焦燥など）
- \(g_t\)：メタ認知の状態（自分の感情を観測できているか）

である．
関数 \(\phi\) は，これらを統合して現在の心理的・環境的状態を表す写像である．

### 3.2 構造的リスクベクトル

内部状態 \(s_t\) は，三つの構造的リスク軸からなるベクトルに変換される．

\[
R_t =
\begin{bmatrix}
b_t \\
u_t \\
\ell_t
\end{bmatrix}
= f_{\theta}(s_t)
\]

ここで，

- \(b_t\)：境界侵害の大きさ  
- \(u_t\)：制御不能性の大きさ  
- \(\ell_t\)：喪失または予期的喪失の大きさ  

を表す．  
関数 \(f_{\theta}\) は，感情と状況からこれらの構造的リスクを推定する翻訳器であり，
人間自身の内省や，あるいは将来的にはAIモデルによって実装される．

### 3.3 介入ポリシーの選択

システムは，次の三種類の介入ポリシーのいずれかを選択する．

\[
k_t \in \{\text{Env}, \text{Inst}, \text{Proc}\}
\]

それぞれ，

- Env：環境の変更  
- Inst：制度・ルールの変更  
- Proc：行動手順の変更  

を意味する．

これらの中から，現在の構造的リスクに対して最も効果的なものが選ばれる．

\[
k_t =
\arg\max_{k}
\left(
w_k^\top R_t + c_k
\right)
\]

ここで，

- \(w_k\)：各介入が三軸リスクをどれだけ減らせるかを表す重み
- \(c_k\)：実行コスト（疲労，対人摩擦など）

である．
これは，「どの種類の設計変更が，今の不安定さを最も減らすか」を評価していると解釈できる．

### 3.4 非介入（NI）の安全弁

すべての問題は設計によって解決できるわけではない．
特に，制御不能性が高く，かつ介入コストが大きい場合，
行動すること自体が不安定化を招く．

そのため，本研究では非介入（NI）を明示的な方策として導入する．

\[
\text{NI}(t)
=
\mathbf{1}
\left(
u_t \ge \tau_u
\;\land\;
C_{\text{int}}(t) \ge \tau_c
\right)
\]

ここで，

- \(C_{\text{int}}(t)\)：現在の介入コスト（疲労・対人負荷など）
- \(\tau_u, \tau_c\)：それぞれの閾値

である．

この条件が成り立つとき，
システムは意図的に「何もしない」ことを選択する．
これは無策ではなく，安定性を守るための戦略的制御である．

## 4. 制御アルゴリズム

本節では，前節で定式化した構造的リスクと介入方策が，
どのような手順で実行されるかをアルゴリズムとして示す．

### 4.1 安定性優先制御ループ

人間の意思決定は，単発の判断ではなく，
時間を通じたフィードバック制御として捉えられる．
本フレームワークでは，以下のループが継続的に実行される．

---

**Algorithm 1: Emotion-Aware Stability-First Control**

1. 外部状態 \(x_t\) と感情信号 \(e_t\) を観測する  
2. メタ認知状態 \(g_t\) を更新する（自分の感情を認識できているか）  
3. 内部状態 \(s_t = \phi(x_t, e_t, g_t)\) を構成する  
4. 構造的リスク \(R_t = f_\theta(s_t)\) を推定する  
5. 介入コスト \(C_{\text{int}}(t)\) を評価する  
6. もし \(NI(t) = 1\) なら  
  a. 介入せず，観測のみを継続する  
  b. 次の時刻へ進む  
7. それ以外の場合  
  a. \(k_t = \arg\max_k (w_k^\top R_t + c_k)\) を計算  
  b. 選択された介入 \(k_t\) を実行  
8. 状態を更新し，次の時刻へ進む  

---

### 4.2 解釈

このアルゴリズムは，「不安を消す」ことを目的としない．  
目的は，構造的リスクが蓄積してシステムが破綻することを防ぐことである．

非介入（NI）が組み込まれていることで，
制御不能で高コストな状況においては，
過剰な努力や自己破壊的な行動が抑制される．

この点が，本フレームワークの安定性優先性の中核である．

## 5. 実験設計と評価指標

本節では，提案フレームワークの有効性を評価するための
実験設計と指標を定義する．
本研究の目的は「幸福度」や「成果」ではなく，
**破綻を防ぎ，安定性を維持できるか**を評価することである．

### 5.1 ベンチマーク条件

以下の三つの意思決定システムを比較対象とする．

1. **感情無視型（Baseline-A）**  
　感情入力を使用せず，出来事 \(x_t\) のみで行動を決定する．

2. **感情反応型（Baseline-B）**  
　感情 \(e_t\) に即時反応して行動を選択するが，構造的分解を行わない．

3. **提案手法（Proposed）**  
　本研究で提案する，三軸構造と非介入を用いた制御モデル．

### 5.2 シナリオ

評価には，現実的な長期ストレスシナリオを用いる．

例：
- 市場変動を伴う資産運用
- 対人摩擦を含む職場環境
- 近隣トラブルや行政対応

各シナリオにおいて，連続的な出来事と感情が入力として与えられる．

### 5.3 評価指標

安定性を以下の指標で評価する．

- **破綻回数**：意思決定が継続不能になるイベントの発生回数  
- **回復時間**：不安定状態から安定状態に戻るまでの時間  
- **累積疲労**：介入コスト \(C_{\text{int}}\) の時間積分  
- **境界侵害時間**：\(b_t\) が高い状態が継続した時間

これらの指標において，
提案手法が他のベースラインよりも
破綻が少なく，回復が速く，累積疲労が低いことが期待される．

## 6. 関連研究

本研究は，心理学，認知科学，制御理論，および人間中心AIの複数分野にまたがる．
ここでは，特に関係の深い研究領域との違いを整理する．

### 6.1 認知行動療法・マインドフルネス

認知行動療法（CBT）やマインドフルネスは，
感情を観察し，自動反応から距離を取る方法を提供している．
これらは，本研究の「メタ認知」に対応する重要な基盤である．

しかしCBTは主に個人の内面に焦点を当てており，
環境・制度・手順といった外部構造を設計対象として扱うことは少ない．
本研究は，感情を外部システムの再設計へと接続する点で異なる．

### 6.2 感情コンピューティング（Affective Computing）

感情コンピューティングは，
音声・表情・生体信号などから感情を推定し，
ユーザ適応型の応答を行う技術である．

これらの研究は感情検出に優れているが，
感情を「破綻リスクの構造」として扱う枠組みは持たない．
本研究は，感情を設計可能なリスクベクトルに翻訳する点に新規性がある．

### 6.3 強化学習と意思決定理論

強化学習は，報酬を最大化する行動方策を学習する枠組みである．
しかし多くの手法は短期的な報酬や効率を最適化し，
長期的な心理的安定性や破綻回避を目的関数に含まない．

本研究は，「破綻しないこと」を第一目的とし，
非介入を明示的な方策として組み込む点で異なる．

### 6.4 人間中心AI・Human-in-the-loop

人間中心AIは，
人間の価値観や負担を考慮したAI設計を目指す．
本研究はこの流れに属するが，
特に「感情を構造的リスクとして扱う」点を明確に定式化した点に特徴がある．

## 7. 議論

### 7.1 倫理的含意

本フレームワークは，人間の感情を単なる誤差やノイズではなく，
保護すべきシステムの安全信号として扱う．
これは，人間を効率最大化の部品として扱うAI設計とは根本的に異なる立場である．

特に非介入（NI）を明示的に導入することで，
「これ以上の最適化は人を壊す」という限界を
システムの一部として組み込む点に倫理的意義がある．

### 7.2 限界

本研究は，構造的リスクの推定 \(f_\theta\) が
人間の自己申告や内省に依存する点で主観性を含む．
また，境界侵害や喪失の評価は個人差が大きく，
普遍的な数値基準を与えることは難しい．

しかし，本フレームワークの目的は
「正確な数値予測」ではなく
「破綻しない方向へ導く構造的判断」にある．

### 7.3 応用可能性

本フレームワークは以下の領域に応用可能である．

- メンタルヘルス支援AI  
- 長期ストレス下での意思決定支援  
- 働き方設計・キャリア設計  
- 資産運用におけるリスク管理  
- 対人関係・生活環境の調整支援  

特に，人間が自らの感情を入力し，
AIが構造的リスクと介入方策を提示する形での
人間中心型意思決定支援への展開が期待される．


